{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efe9a2fa",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfd15c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\visualizacionAvanzada\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Descargar dataset desde Kaggle\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil  \n",
    "import warnings\n",
    "# Importaciones para el manejo geoespacial\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import subprocess \n",
    "\n",
    "# Desactivar advertencias de sjoin\n",
    "warnings.filterwarnings('ignore', 'The CRS of the two GeoDataFrames are not the same. *')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c205aa37",
   "metadata": {},
   "source": [
    "# ðŸ› ï¸ Utilidades\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b83070",
   "metadata": {},
   "source": [
    "## Busqueda de distrito a partir de coordenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4d19b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PROCESAMIENTO GEOESPACIAL ---\n",
    "\n",
    "def assign_borough_from_geometry(df: pd.DataFrame, lat_col: str, lon_col: str, output_col: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Asigna el distrito (borough) a las coordenadas usando una uniÃ³n espacial.\n",
    "    \n",
    "    Argumentos:\n",
    "        df (pd.DataFrame): DataFrame de entrada.\n",
    "        lat_col (str): Nombre de la columna de latitud.\n",
    "        lon_col (str): Nombre de la columna de longitud.\n",
    "        output_col (str): Nombre de la nueva columna de distrito a crear.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Iniciando asignaciÃ³n de distrito para {output_col} ---\")\n",
    "    \n",
    "    # 1. Cargar lÃ­mites de distritos de NYC (Boroughs)\n",
    "    nyc_boundaries_url = \"https://data.cityofnewyork.us/resource/gthc-hcne.geojson\"\n",
    "    \n",
    "    try:\n",
    "        boroughs_gdf = gpd.read_file(nyc_boundaries_url)\n",
    "        \n",
    "        boroughs_gdf = boroughs_gdf.set_geometry('geometry')\n",
    "\n",
    "        # Renombrar la columna del distrito en el GeoDataFrame de lÃ­mites\n",
    "        boroughs_gdf.rename(columns={'boroname': 'borough_name_geo'}, inplace=True)\n",
    "        \n",
    "        if boroughs_gdf.crs is None:\n",
    "             boroughs_gdf.set_crs(epsg=4326, inplace=True)\n",
    "        else:\n",
    "             boroughs_gdf = boroughs_gdf.to_crs(epsg=4326)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error CRÃTICO al cargar o procesar los lÃ­mites de los distritos: {e}\")\n",
    "        return df\n",
    "\n",
    "    # 2. Convertir datos de Uber a GeoDataFrame\n",
    "    df[lat_col] = pd.to_numeric(df[lat_col], errors='coerce')\n",
    "    df[lon_col] = pd.to_numeric(df[lon_col], errors='coerce')\n",
    "    \n",
    "    df_clean = df.dropna(subset=[lat_col, lon_col]).copy()\n",
    "    \n",
    "    if df_clean.empty:\n",
    "        print(\"No hay coordenadas vÃ¡lidas para procesar.\")\n",
    "        df[output_col] = 'Out of NYC/Unknown'\n",
    "        return df\n",
    "\n",
    "    geometry = [Point(xy) for xy in zip(df_clean[lon_col], df_clean[lat_col])]\n",
    "    points_gdf = gpd.GeoDataFrame(df_clean, geometry=geometry, crs=\"EPSG:4326\")\n",
    "    \n",
    "    # 3. Realizar UniÃ³n Espacial (Spatial Join)\n",
    "    if points_gdf.crs != boroughs_gdf.crs:\n",
    "        boroughs_gdf = boroughs_gdf.to_crs(points_gdf.crs)\n",
    "\n",
    "    join_result = gpd.sjoin(points_gdf, boroughs_gdf[['borough_name_geo', 'geometry']], how=\"left\", predicate=\"within\")\n",
    "    \n",
    "    # 4. Mapear el resultado de nuevo al DataFrame original\n",
    "    # Usar el nombre de columna dinÃ¡mico (output_col)\n",
    "    df[output_col] = join_result['borough_name_geo'].reindex(df.index)\n",
    "    \n",
    "    # 5. Rellenar valores faltantes (coordenadas fuera de NYC o invÃ¡lidas)\n",
    "    df[output_col] = df[output_col].fillna('Out of NYC/Unknown')\n",
    "    \n",
    "    print(f\"--- AsignaciÃ³n de distrito ({output_col}) completada ---\")\n",
    "    print(f\"Top 5 de distritos encontrados para {output_col}:\")\n",
    "    print(df[output_col].value_counts().head(5))\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07604485",
   "metadata": {},
   "source": [
    "## Estimacion de la emision de CO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89ba9c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Supuestos ---\n",
    "FUEL_DENSITY_KG_PER_L = 0.74      # masa por litro (gasolina), ~0.74 kg/L (ver fuente)\n",
    "CO2_PER_LITRE_KG = 2.0844         # ejemplo (DEFRA condensed set): kg CO2 por litro de gasolina\n",
    "\n",
    "# --- Funciones basadas en EMEP/COPERT (ejemplo para gasolina ligera) ---\n",
    "def fuel_g_per_km_emep_petrol(V_kmh: float) -> float:\n",
    "    \"\"\"\n",
    "    FÃ³rmula de la guÃ­a EMEP/COPERT (ejemplo para coches <1.4 L en rango ~17.9-130 km/h).\n",
    "    Devuelve consumo de combustible en gramos por km (g/km).\n",
    "    Si la velocidad estÃ¡ fuera del rango razonable, aplicamos lÃ­mites.\n",
    "    Fuente: EMEP/EEA (COPERT) guidebook.\n",
    "    \"\"\"\n",
    "    if np.isnan(V_kmh) or V_kmh <= 0:\n",
    "        return np.nan\n",
    "    # rango tÃ­pico: si V < 10 o > 130 podemos saturar o usar una aproximaciÃ³n\n",
    "    V = float(np.clip(V_kmh, 10.0, 130.0))\n",
    "    # ecuaciÃ³n extraÃ­da (ver guÃ­a): consumo (g/km) = 81.1 - 1.014*V + 0.0068*V^2\n",
    "    return 81.1 - 1.014 * V + 0.0068 * V**2\n",
    "\n",
    "def co2_per_km_from_speed(V_kmh: float,\n",
    "                          fuel_density_kg_per_l=FUEL_DENSITY_KG_PER_L,\n",
    "                          co2_per_litre_kg=CO2_PER_LITRE_KG) -> float:\n",
    "    \"\"\"\n",
    "    Calcula kg CO2 por km usando la ecuaciÃ³n de consumo + conversiones.\n",
    "    \"\"\"\n",
    "    fuel_g_km = fuel_g_per_km_emep_petrol(V_kmh)   # g fuel / km (masa)\n",
    "    if np.isnan(fuel_g_km):\n",
    "        return np.nan\n",
    "    fuel_kg_km = fuel_g_km / 1000.0               # kg fuel / km\n",
    "    fuel_l_km = fuel_kg_km / fuel_density_kg_per_l  # L fuel / km\n",
    "    co2_kg_km = fuel_l_km * co2_per_litre_kg\n",
    "    return co2_kg_km\n",
    "\n",
    "# --- Pipeline para un dataframe ---\n",
    "def estimate_co2_dataframe(df: pd.DataFrame,\n",
    "                           distance_col='trip_distance_km',\n",
    "                           minutes_col='trip_minutes',\n",
    "                           passengers_col='passenger_count'):\n",
    "    df = df.copy()\n",
    "    # velocidad media km/h\n",
    "    df['avg_speed_kmh'] = df[distance_col] / (df[minutes_col] / 60.0)\n",
    "    # consumo / emisiones por km\n",
    "    df['fuel_g_per_km'] = df['avg_speed_kmh'].apply(fuel_g_per_km_emep_petrol)\n",
    "    df['co2_kg_per_km'] = df['avg_speed_kmh'].apply(co2_per_km_from_speed)\n",
    "    # total por viaje\n",
    "    df['co2_kg_trip'] = df['co2_kg_per_km'] * df[distance_col]\n",
    "    # por pasajero (si passenger_count==0 lo tratamos como 1)\n",
    "    df['passenger_count_safe'] = df[passengers_col].replace({0:1}).fillna(1)\n",
    "    df['co2_kg_per_passenger'] = df['co2_kg_trip'] / df['passenger_count_safe']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d207eeb0",
   "metadata": {},
   "source": [
    "# ðŸ”¢ Proceso principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "242d78a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/praveenluppunda/uber-dataset?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.90M/3.90M [00:00<00:00, 4.70MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\aesto\\.cache\\kagglehub\\datasets\\praveenluppunda\\uber-dataset\\versions\\1\n",
      "Archivo CSV encontrado: C:\\Users\\aesto\\.cache\\kagglehub\\datasets\\praveenluppunda\\uber-dataset\\versions\\1\\uber_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Descargar la versiÃ³n mÃ¡s reciente\n",
    "path = kagglehub.dataset_download(\"praveenluppunda/uber-dataset\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Buscar archivo CSV en el directorio descargado\n",
    "csv_files = [f for f in os.listdir(path) if f.endswith('.csv')]\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(\"No se encontrÃ³ ningÃºn archivo CSV en el dataset.\")\n",
    "    \n",
    "file_path = os.path.join(path, csv_files[0])\n",
    "print(\"Archivo CSV encontrado:\", file_path)\n",
    "\n",
    "# Cargar dataset\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a2f9ac",
   "metadata": {},
   "source": [
    "## Eliminar puntos con coordenadas (0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e478bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Limpieza de datos (Coordenadas ~0,0) ---\n",
      "Registros iniciales: 100000\n",
      "Registros eliminados (cerca de 0,0): 1000\n",
      "Registros restantes: 99000\n"
     ]
    }
   ],
   "source": [
    "# 0.1. FILTRO DE COORDENADAS (lat/lon ~ 0,0) \n",
    "# Primero, asegurar que las coordenadas son numÃ©ricas para el filtro\n",
    "df['pickup_latitude'] = pd.to_numeric(df['pickup_latitude'], errors='coerce')\n",
    "df['pickup_longitude'] = pd.to_numeric(df['pickup_longitude'], errors='coerce')\n",
    "df['dropoff_latitude'] = pd.to_numeric(df['dropoff_latitude'], errors='coerce')\n",
    "df['dropoff_longitude'] = pd.to_numeric(df['dropoff_longitude'], errors='coerce')\n",
    "\n",
    "# Definir el umbral (e.g., +/- 0.1 grados de latitud y longitud)\n",
    "ZERO_THRESHOLD = 0.1 \n",
    "\n",
    "# Crear mÃ¡scaras para identificar registros que tienen un pickup o dropoff cerca de (0,0)\n",
    "is_pickup_zero = (abs(df['pickup_latitude']) < ZERO_THRESHOLD) & (abs(df['pickup_longitude']) < ZERO_THRESHOLD)\n",
    "is_dropoff_zero = (abs(df['dropoff_latitude']) < ZERO_THRESHOLD) & (abs(df['dropoff_longitude']) < ZERO_THRESHOLD)\n",
    "\n",
    "# Combinar las mÃ¡scaras: filtrar si CUALQUIERA de las ubicaciones estÃ¡ cerca de (0,0)\n",
    "df_clean = df[~(is_pickup_zero | is_dropoff_zero)].copy()\n",
    "\n",
    "# Mostrar cuÃ¡ntos registros se eliminaron\n",
    "rows_removed = len(df) - len(df_clean)\n",
    "print(f\"\\n--- Limpieza de datos (Coordenadas ~0,0) ---\")\n",
    "print(f\"Registros iniciales: {len(df)}\")\n",
    "print(f\"Registros eliminados (cerca de 0,0): {rows_removed}\")\n",
    "print(f\"Registros restantes: {len(df_clean)}\")\n",
    "\n",
    "df = df_clean # Quitamos los errores de coordenadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f167fc",
   "metadata": {},
   "source": [
    "## Obtener los distritos de salida y llegada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e499c6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iniciando asignaciÃ³n de distrito para pickup_borough ---\n",
      "--- AsignaciÃ³n de distrito (pickup_borough) completada ---\n",
      "Top 5 de distritos encontrados para pickup_borough:\n",
      "pickup_borough\n",
      "Manhattan             90973\n",
      "Queens                 5984\n",
      "Brooklyn               1852\n",
      "Bronx                   100\n",
      "Out of NYC/Unknown       89\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Iniciando asignaciÃ³n de distrito para dropoff_borough ---\n",
      "--- AsignaciÃ³n de distrito (dropoff_borough) completada ---\n",
      "Top 5 de distritos encontrados para dropoff_borough:\n",
      "dropoff_borough\n",
      "Manhattan             86560\n",
      "Queens                 6774\n",
      "Brooklyn               4429\n",
      "Bronx                   711\n",
      "Out of NYC/Unknown      505\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 0.2. Asignar distrito (borough) a las coordenadas\n",
    "# Asignar distrito de SALIDA\n",
    "if 'pickup_latitude' in df.columns and 'pickup_longitude' in df.columns:\n",
    "    df = assign_borough_from_geometry(df, 'pickup_latitude', 'pickup_longitude', 'pickup_borough')\n",
    "    \n",
    "# Asignar distrito de LLEGADA\n",
    "if 'dropoff_latitude' in df.columns and 'dropoff_longitude' in df.columns:\n",
    "    df = assign_borough_from_geometry(df, 'dropoff_latitude', 'dropoff_longitude', 'dropoff_borough')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880f65e0",
   "metadata": {},
   "source": [
    "## Otras transformaciones\n",
    "\n",
    "Obtener el nombre de las caracterÃ­sticas a partir de la tabla de informaciÃ³n sobre los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd821ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Eliminar columna VendorID\n",
    "if 'VendorID' in df.columns:\n",
    "    df = df.drop(columns=['VendorID'])\n",
    "\n",
    "# 2. Calcular minutos de viaje\n",
    "df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
    "df['trip_minutes'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "\n",
    "# 3. Convertir distancia de millas a kilÃ³metros\n",
    "if 'trip_distance' in df.columns:\n",
    "    df['trip_distance_km'] = df['trip_distance'] * 1.60934\n",
    "    df = df.drop(columns=['trip_distance'])\n",
    "\n",
    "# 4. Transformar RatecodeID a categorÃ­as\n",
    "ratecode_map = {\n",
    "    1: \"Standard rate\",\n",
    "    2: \"JFK\",\n",
    "    3: \"Newark\",\n",
    "    4: \"Nassau or Westchester\",\n",
    "    5: \"Negotiated fare\",\n",
    "    6: \"Group ride\",\n",
    "    99: \"Null/unknown\"\n",
    "}\n",
    "if 'RatecodeID' in df.columns:\n",
    "    df['RatecodeID'] = df['RatecodeID'].map(ratecode_map)\n",
    "\n",
    "# 5. Eliminar columna store_and_fwd_flag\n",
    "if 'store_and_fwd_flag' in df.columns:\n",
    "    df = df.drop(columns=['store_and_fwd_flag'])\n",
    "\n",
    "# 6. Transformar payment_type a categorÃ­as\n",
    "payment_type_map = {\n",
    "    0: \"Flex Fare trip\",\n",
    "    1: \"Credit card\",\n",
    "    2: \"Cash\",\n",
    "    3: \"No charge\",\n",
    "    4: \"Dispute\",\n",
    "    5: \"Unknown\",\n",
    "    6: \"Voided trip\"\n",
    "}\n",
    "if 'payment_type' in df.columns:\n",
    "    df['payment_type'] = df['payment_type'].map(payment_type_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d07f23",
   "metadata": {},
   "source": [
    "## Calcular datos de emisiones de CO2\n",
    "**CÃ³mo se han calculado las emisiones de CO2:**\n",
    "\n",
    "\n",
    "1. **FunciÃ³n de consumo de combustible dependiente de la velocidad**\n",
    "    (Ejemplo basado en ecuaciÃ³n EMEP/COPERT para coches gasolina pequeÃ±os)\n",
    "\n",
    "    $$\n",
    "    \\text{consumo\\_combustible\\_g\\_por\\_km} = 81.1 - 1.014 \\cdot V + 0.0068 \\cdot V^2\n",
    "    $$\n",
    "\n",
    "    VÃ¡lida en el rango aproximado de **17.9â€“130 km/h** (ver guÃ­a EMEP/COPERT).  \n",
    "    *Fuente: Agencia Europea del Medio Ambiente*\n",
    "\n",
    "2. **ConversiÃ³n de gramos de combustible a litros por kilÃ³metro**\n",
    "\n",
    "    $$\n",
    "    \\text{litros\\_por\\_km} = \\frac{\\text{consumo\\_g\\_por\\_km} / 1000}{\\rho_{\\text{combustible}}}\n",
    "    $$\n",
    "\n",
    "    donde  \n",
    "    $$\n",
    "    \\rho_{\\text{gasolina}} \\approx 0.74 \\, \\text{kg/L}\n",
    "    $$\n",
    "\n",
    "    *Fuente: toolkit.pops.int*\n",
    "\n",
    "3. **ConversiÃ³n de litros a kgCOâ‚‚ (segÃºn factor DEFRA)**\n",
    "\n",
    "    $$\n",
    "    \\text{kgCO2\\_por\\_km} = \\text{litros\\_por\\_km} \\times \\text{kgCO2\\_por\\_litro}\n",
    "    $$\n",
    "\n",
    "    Usar el valor exacto del **spreadsheet DEFRA** para el aÃ±o y tipo de combustible correspondiente.  \n",
    "    *Fuente: GOV.UK*\n",
    "\n",
    "4. **Emisiones totales y por pasajero**\n",
    "\n",
    "    $$\n",
    "    \\text{emisiones\\_por\\_viaje} = \\text{kgCO2\\_por\\_km} \\times \\text{trip\\_distance\\_km}\n",
    "    $$\n",
    "\n",
    "    $$\n",
    "    \\text{emisiones\\_por\\_pasajero} = \\frac{\\text{emisiones\\_por\\_viaje}}{\\max(1, \\text{passenger\\_count})}\n",
    "    $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0f7b83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = estimate_co2_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e1ee14",
   "metadata": {},
   "source": [
    "# ðŸ—ƒï¸ Guardar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "731ce39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Archivo procesado guardado como: uber_dataset_con_distritos.csv\n",
      "Directorio temporal eliminado: C:\\Users\\aesto\\.cache\\kagglehub\\datasets\\praveenluppunda\\uber-dataset\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "# 7. Guardar el archivo final\n",
    "output_file = \"uber_dataset_con_distritos.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"\\nArchivo procesado guardado como: {output_file}\")\n",
    "\n",
    "# 8. Eliminar el directorio temporal de descarga\n",
    "shutil.rmtree(path)\n",
    "print(f\"Directorio temporal eliminado: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb47a057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "fecha",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "0171e48d-4731-4e7c-92bd-615d6072e732",
       "rows": [
        [
         "8",
         "11606"
        ],
        [
         "9",
         "10617"
        ],
        [
         "12",
         "10421"
        ],
        [
         "13",
         "10124"
        ],
        [
         "10",
         "9538"
        ],
        [
         "11",
         "9532"
        ],
        [
         "7",
         "9480"
        ],
        [
         "0",
         "6959"
        ],
        [
         "14",
         "4825"
        ],
        [
         "1",
         "4089"
        ],
        [
         "5",
         "3639"
        ],
        [
         "2",
         "2562"
        ],
        [
         "4",
         "1888"
        ],
        [
         "6",
         "1876"
        ],
        [
         "3",
         "1844"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 15
       }
      },
      "text/plain": [
       "fecha\n",
       "8     11606\n",
       "9     10617\n",
       "12    10421\n",
       "13    10124\n",
       "10     9538\n",
       "11     9532\n",
       "7      9480\n",
       "0      6959\n",
       "14     4825\n",
       "1      4089\n",
       "5      3639\n",
       "2      2562\n",
       "4      1888\n",
       "6      1876\n",
       "3      1844\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fecha'] = df['tpep_pickup_datetime'].dt.hour\n",
    "df['fecha'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
