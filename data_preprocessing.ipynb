{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efe9a2fa",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfd15c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/praveenluppunda/uber-dataset?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3.90M/3.90M [00:00<00:00, 4.88MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\aesto\\.cache\\kagglehub\\datasets\\praveenluppunda\\uber-dataset\\versions\\1\n",
      "Archivo CSV encontrado: C:\\Users\\aesto\\.cache\\kagglehub\\datasets\\praveenluppunda\\uber-dataset\\versions\\1\\uber_data.csv\n",
      "\n",
      "--- Limpieza de datos (Coordenadas ~0,0) ---\n",
      "Registros iniciales: 10000\n",
      "Registros eliminados (cerca de 0,0): 74\n",
      "Registros restantes: 9926\n",
      "\n",
      "--- Iniciando asignación de distrito para pickup_borough ---\n",
      "--- Asignación de distrito (pickup_borough) completada ---\n",
      "Top 5 de distritos encontrados para pickup_borough:\n",
      "pickup_borough\n",
      "Manhattan             9259\n",
      "Queens                 474\n",
      "Brooklyn               181\n",
      "Out of NYC/Unknown       6\n",
      "Bronx                    6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Iniciando asignación de distrito para dropoff_borough ---\n",
      "--- Asignación de distrito (dropoff_borough) completada ---\n",
      "Top 5 de distritos encontrados para dropoff_borough:\n",
      "dropoff_borough\n",
      "Manhattan             9209\n",
      "Queens                 461\n",
      "Brooklyn               169\n",
      "Bronx                   50\n",
      "Out of NYC/Unknown      36\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Archivo procesado guardado como: uber_dataset_con_distritos.csv\n",
      "Directorio temporal eliminado: C:\\Users\\aesto\\.cache\\kagglehub\\datasets\\praveenluppunda\\uber-dataset\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "# Descargar dataset desde Kaggle\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil  \n",
    "import warnings\n",
    "# Importaciones para el manejo geoespacial\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import subprocess \n",
    "\n",
    "# Desactivar advertencias de sjoin\n",
    "warnings.filterwarnings('ignore', 'The CRS of the two GeoDataFrames are not the same. *')\n",
    "\n",
    "# --- PROCESAMIENTO GEOESPACIAL ---\n",
    "\n",
    "def assign_borough_from_geometry(df: pd.DataFrame, lat_col: str, lon_col: str, output_col: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Asigna el distrito (borough) a las coordenadas usando una unión espacial.\n",
    "    \n",
    "    Argumentos:\n",
    "        df (pd.DataFrame): DataFrame de entrada.\n",
    "        lat_col (str): Nombre de la columna de latitud.\n",
    "        lon_col (str): Nombre de la columna de longitud.\n",
    "        output_col (str): Nombre de la nueva columna de distrito a crear.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Iniciando asignación de distrito para {output_col} ---\")\n",
    "    \n",
    "    # 1. Cargar límites de distritos de NYC (Boroughs)\n",
    "    nyc_boundaries_url = \"https://data.cityofnewyork.us/resource/gthc-hcne.geojson\"\n",
    "    \n",
    "    try:\n",
    "        boroughs_gdf = gpd.read_file(nyc_boundaries_url)\n",
    "        \n",
    "        boroughs_gdf = boroughs_gdf.set_geometry('geometry')\n",
    "\n",
    "        # Renombrar la columna del distrito en el GeoDataFrame de límites\n",
    "        boroughs_gdf.rename(columns={'boroname': 'borough_name_geo'}, inplace=True)\n",
    "        \n",
    "        if boroughs_gdf.crs is None:\n",
    "             boroughs_gdf.set_crs(epsg=4326, inplace=True)\n",
    "        else:\n",
    "             boroughs_gdf = boroughs_gdf.to_crs(epsg=4326)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error CRÍTICO al cargar o procesar los límites de los distritos: {e}\")\n",
    "        return df\n",
    "\n",
    "    # 2. Convertir datos de Uber a GeoDataFrame\n",
    "    df[lat_col] = pd.to_numeric(df[lat_col], errors='coerce')\n",
    "    df[lon_col] = pd.to_numeric(df[lon_col], errors='coerce')\n",
    "    \n",
    "    df_clean = df.dropna(subset=[lat_col, lon_col]).copy()\n",
    "    \n",
    "    if df_clean.empty:\n",
    "        print(\"No hay coordenadas válidas para procesar.\")\n",
    "        df[output_col] = 'Out of NYC/Unknown'\n",
    "        return df\n",
    "\n",
    "    geometry = [Point(xy) for xy in zip(df_clean[lon_col], df_clean[lat_col])]\n",
    "    points_gdf = gpd.GeoDataFrame(df_clean, geometry=geometry, crs=\"EPSG:4326\")\n",
    "    \n",
    "    # 3. Realizar Unión Espacial (Spatial Join)\n",
    "    if points_gdf.crs != boroughs_gdf.crs:\n",
    "        boroughs_gdf = boroughs_gdf.to_crs(points_gdf.crs)\n",
    "\n",
    "    join_result = gpd.sjoin(points_gdf, boroughs_gdf[['borough_name_geo', 'geometry']], how=\"left\", predicate=\"within\")\n",
    "    \n",
    "    # 4. Mapear el resultado de nuevo al DataFrame original\n",
    "    # Usar el nombre de columna dinámico (output_col)\n",
    "    df[output_col] = join_result['borough_name_geo'].reindex(df.index)\n",
    "    \n",
    "    # 5. Rellenar valores faltantes (coordenadas fuera de NYC o inválidas)\n",
    "    df[output_col] = df[output_col].fillna('Out of NYC/Unknown')\n",
    "    \n",
    "    print(f\"--- Asignación de distrito ({output_col}) completada ---\")\n",
    "    print(f\"Top 5 de distritos encontrados para {output_col}:\")\n",
    "    print(df[output_col].value_counts().head(5))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# --- SCRIPT PRINCIPAL ---\n",
    "\n",
    "# Descargar la versión más reciente\n",
    "path = kagglehub.dataset_download(\"praveenluppunda/uber-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Buscar archivo CSV en el directorio descargado\n",
    "csv_files = [f for f in os.listdir(path) if f.endswith('.csv')]\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(\"No se encontró ningún archivo CSV en el dataset.\")\n",
    "    \n",
    "file_path = os.path.join(path, csv_files[0])\n",
    "print(\"Archivo CSV encontrado:\", file_path)\n",
    "\n",
    "# Cargar dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# --- TRANSFORMACIONES ---\n",
    "\n",
    "df = df.head(10000).copy() \n",
    "\n",
    "# 0.1. FILTRO DE COORDENADAS (lat/lon ~ 0,0) (¡NUEVO!)\n",
    "# Primero, asegurar que las coordenadas son numéricas para el filtro\n",
    "df['pickup_latitude'] = pd.to_numeric(df['pickup_latitude'], errors='coerce')\n",
    "df['pickup_longitude'] = pd.to_numeric(df['pickup_longitude'], errors='coerce')\n",
    "df['dropoff_latitude'] = pd.to_numeric(df['dropoff_latitude'], errors='coerce')\n",
    "df['dropoff_longitude'] = pd.to_numeric(df['dropoff_longitude'], errors='coerce')\n",
    "\n",
    "# Definir el umbral (e.g., +/- 0.1 grados de latitud y longitud)\n",
    "ZERO_THRESHOLD = 0.1 \n",
    "\n",
    "# Crear máscaras para identificar registros que tienen un pickup o dropoff cerca de (0,0)\n",
    "is_pickup_zero = (abs(df['pickup_latitude']) < ZERO_THRESHOLD) & (abs(df['pickup_longitude']) < ZERO_THRESHOLD)\n",
    "is_dropoff_zero = (abs(df['dropoff_latitude']) < ZERO_THRESHOLD) & (abs(df['dropoff_longitude']) < ZERO_THRESHOLD)\n",
    "\n",
    "# Combinar las máscaras: filtrar si CUALQUIERA de las ubicaciones está cerca de (0,0)\n",
    "df_clean = df[~(is_pickup_zero | is_dropoff_zero)].copy()\n",
    "\n",
    "# Mostrar cuántos registros se eliminaron\n",
    "rows_removed = len(df) - len(df_clean)\n",
    "print(f\"\\n--- Limpieza de datos (Coordenadas ~0,0) ---\")\n",
    "print(f\"Registros iniciales: {len(df)}\")\n",
    "print(f\"Registros eliminados (cerca de 0,0): {rows_removed}\")\n",
    "print(f\"Registros restantes: {len(df_clean)}\")\n",
    "\n",
    "df = df_clean # Usar el DataFrame limpio para el resto de las transformaciones\n",
    "\n",
    "# 0.2. Asignar distrito (borough) a las coordenadas\n",
    "# Asignar distrito de SALIDA\n",
    "if 'pickup_latitude' in df.columns and 'pickup_longitude' in df.columns:\n",
    "    df = assign_borough_from_geometry(df, 'pickup_latitude', 'pickup_longitude', 'pickup_borough')\n",
    "    \n",
    "# Asignar distrito de LLEGADA\n",
    "if 'dropoff_latitude' in df.columns and 'dropoff_longitude' in df.columns:\n",
    "    df = assign_borough_from_geometry(df, 'dropoff_latitude', 'dropoff_longitude', 'dropoff_borough')\n",
    "    \n",
    "# 1. Eliminar columna VendorID\n",
    "if 'VendorID' in df.columns:\n",
    "    df = df.drop(columns=['VendorID'])\n",
    "\n",
    "# 2. Calcular minutos de viaje\n",
    "df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
    "df['trip_minutes'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "\n",
    "# 3. Convertir distancia de millas a kilómetros\n",
    "if 'trip_distance' in df.columns:\n",
    "    df['trip_distance_km'] = df['trip_distance'] * 1.60934\n",
    "    df = df.drop(columns=['trip_distance'])\n",
    "\n",
    "# 4. Transformar RatecodeID a categorías\n",
    "ratecode_map = {\n",
    "    1: \"Standard rate\",\n",
    "    2: \"JFK\",\n",
    "    3: \"Newark\",\n",
    "    4: \"Nassau or Westchester\",\n",
    "    5: \"Negotiated fare\",\n",
    "    6: \"Group ride\",\n",
    "    99: \"Null/unknown\"\n",
    "}\n",
    "if 'RatecodeID' in df.columns:\n",
    "    df['RatecodeID'] = df['RatecodeID'].map(ratecode_map)\n",
    "\n",
    "# 5. Eliminar columna store_and_fwd_flag\n",
    "if 'store_and_fwd_flag' in df.columns:\n",
    "    df = df.drop(columns=['store_and_fwd_flag'])\n",
    "\n",
    "# 6. Transformar payment_type a categorías\n",
    "payment_type_map = {\n",
    "    0: \"Flex Fare trip\",\n",
    "    1: \"Credit card\",\n",
    "    2: \"Cash\",\n",
    "    3: \"No charge\",\n",
    "    4: \"Dispute\",\n",
    "    5: \"Unknown\",\n",
    "    6: \"Voided trip\"\n",
    "}\n",
    "if 'payment_type' in df.columns:\n",
    "    df['payment_type'] = df['payment_type'].map(payment_type_map)\n",
    "\n",
    "# 7. Guardar el archivo final\n",
    "output_file = \"uber_dataset_con_distritos.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"\\nArchivo procesado guardado como: {output_file}\")\n",
    "\n",
    "# 8. Eliminar el directorio temporal de descarga\n",
    "shutil.rmtree(path)\n",
    "print(f\"Directorio temporal eliminado: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55b8ada4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "payment_type\n",
      "Credit card    7258\n",
      "Cash           2658\n",
      "No charge         7\n",
      "Dispute           3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.payment_type.value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visualizacionAvanzada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
